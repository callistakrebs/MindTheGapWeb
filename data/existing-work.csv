model,benchmark,size,modality,domain,task
DINOv2,ImageNet-1K,1_281_167,vision,general,classification
DINOv2,ImageNet-Adversarial,1_281_167,vision,general,classification
DINOv2,ADE-20K,20_000,vision,general,semantic_segmentation
DINOv2,iNat2018,579_184,vision,ecology,classification
DINOv2,iNat2021,2_700_000,vision,ecology,classification
DINOv2,Places205,2_500_000,vision,general,classification
DINOv2,Kinetics400,245_495,vision,general,classification
DINOv2,UCF101,9_537,vision,general,classification
DINOv2,SomethingSomethingV2,168_913,vision,general,classification
DINOv2,Cityscapes,2_975,vision,general,semantic_segmentation
DINOv2,Pascal VOC 2012,5_717,vision,general,object_detection
DINOv2,Food-101,75_750,vision,general,classification
DINOv2,CIFAR-10,50_000,vision,general,classification
DINOv2,CIFAR-100,50_000,vision,general,classification
DINOv2,SUN397,19_850,vision,general,classification
DINOv2,Stanford Cars,8_144,vision,general,classification
DINOv2,FGCV Aircraft,6_667,vision,general,classification
DINOv2,Pascal VOC 2007,5_011,vision,general,object_detection
DINOv2,Textures,3_760,vision,general,classification
DINOv2,Oxford-IIIT Pets,3_680,vision,general,classification
DINOv2,Caltech-101,3_060,vision,general,classification
DINOv2,Oxford Flowers 102,2_040,vision,general,classification
DINOv2,KITTI,6_770,vision,general,depth_estimation
SigLIP,ImageNet-1K,0,vision,general,classification
SigLIP,ImageNet-1K,10_000,vision,general,classification
SigLIP2,ImageNet-1K,0,vision,general,classification
SigLIP2,ImageNet-1K,10_000,vision,general,classification
SigLIP2,AI2 Diagram,12_413,multimodal,general,visual_question_answering
SigLIP2,AOKVQA-DA,18_201,multimodal,general,visual_question_answering
SigLIP2,AOKVQA-MC,18_201,multimodal,general,visual_question_answering
SigLIP2,COCO-35L (avg34),113_287,multimodal,general,image_captioning
SigLIP2,COCO-35L (en),113_287,multimodal,general,image_captioning
SigLIP2,COCOCap,113_287,multimodal,general,image_captioning
SigLIP2,CountBenchQA,0,multimodal,general,counting
SigLIP2,DocVQA,44_812,multimodal,general,visual_question_answering
SigLIP2,GQA,1_075_062,multimodal,general,visual_question_answering
SigLIP2,InfoVQA,26_747,multimodal,general,visual_question_answering
SigLIP2,NLVR2,93_355,multimodal,general,visual_question_answering
SigLIP2,NoCaps,0,multimodal,general,image_captioning
SigLIP2,OCR-VQA,901_717,multimodal,general,visual_question_answering
SigLIP2,OKVQA,9_009,multimodal,general,visual_question_answering
SigLIP2,ST-VQA,26_074,multimodal,general,visual_question_answering
SigLIP2,SciCap,120_188,multimodal,science,image_captioning
SigLIP2,ScienceQA,8_315,multimodal,science,visual_question_answering
SigLIP2,Screen2Words,18_107,multimodal,UI,image_captioning
SigLIP2,TallyQA (complex),249_318,multimodal,general,counting
SigLIP2,TallyQA (simple),249_318,multimodal,general,counting
SigLIP2,TextCaps,21_953,multimodal,general,image_captioning
SigLIP2,TextVQA,34_602,multimodal,general,visual_question_answering
SigLIP2,VQAv2,658_111,multimodal,general,visual_question_answering
SigLIP2,VizWizVQA,24_842,multimodal,general,visual_question_answering
SigLIP2,WidgetCap,44_704,multimodal,UI,image_captioning
SigLIP2,XM3600 (avg35),0,multimodal,general,image_captioning
SigLIP2,XM3600 (en),0,multimodal,general,image_captioning
CLIP,aYahoo,0,multimodal,general,object_detection
CLIP,SUN397,0,vision,general,classification
CLIP,Food-101,75_750,vision,general,classification
CLIP,CIFAR-10,50_000,vision,general,classification
CLIP,CIFAR-100,50_000,vision,general,classification
CLIP,Birdsnap,42_283,vision,ecology,classification
CLIP,SUN397,19_850,vision,general,classification
CLIP,Stanford Cars,8_144,vision,general,classification
CLIP,FGCV Aircraft,6_667,vision,general,classification
CLIP,Pascal VOC 2007,5_011,vision,general,object_detection
CLIP,Textures,3_760,vision,general,classification
CLIP,Oxford-IIIT Pets,3_680,vision,general,classification
CLIP,Caltech-101,3_060,vision,general,classification
CLIP,Oxford Flowers 102,2_040,vision,general,classification
CLIP,MNIST,60_000,vision,general,classification
CLIP,Facial Emotion Recognition 2013,32_140,vision,general,classification
CLIP,STL-10,1_000,vision,general,classification
CLIP,EuroSAT,10_000,vision,satellite_imagery,classification
CLIP,RESISC45,3_150,vision,satellite_imagery,classification
CLIP,GTSRB,26_640,vision,general,classification
CLIP,KITTI,6_770,vision,general,depth_estimation
CLIP,Country211,43_200,vision,general,classification
CLIP,PatchCamelyon,294_912,vision,medical,classification
CLIP,UCF101,9_537,vision,general,classification
CLIP,Kinetics700,494_801,vision,general,classification
CLIP,CLEVR Counts,2_000,vision,general,visual_question_answering
CLIP,Hateful Memes,8_500,multimodal,general,classification
CLIP,Rendered SST2,7_792,multimodal,general,optical_character_recognition
CLIP,ImageNet-1K,1_281_167,vision,general,classification
CLIP,Food-101,0,vision,general,classification
CLIP,CIFAR-10,0,vision,general,classification
CLIP,CIFAR-100,0,vision,general,classification
CLIP,Birdsnap,0,vision,ecology,classification
CLIP,SUN397,0,vision,general,classification
CLIP,Stanford Cars,0,vision,general,classification
CLIP,FGCV Aircraft,0,vision,general,classification
CLIP,Pascal VOC 2007,0,vision,general,object_detection
CLIP,Textures,0,vision,general,classification
CLIP,Oxford-IIIT Pets,0,vision,general,classification
CLIP,Caltech-101,0,vision,general,classification
CLIP,Oxford Flowers 102,0,vision,general,classification
CLIP,MNIST,0,vision,general,classification
CLIP,Facial Emotion Recognition 2013,0,vision,general,classification
CLIP,STL-10,0,vision,general,classification
CLIP,EuroSAT,0,vision,satellite_imagery,classification
CLIP,RESISC45,0,vision,satellite_imagery,classification
CLIP,GTSRB,0,vision,general,classification
CLIP,KITTI,0,vision,general,depth_estimation
CLIP,Country211,0,vision,general,classification
CLIP,PatchCamelyon,0,vision,medical,classification
CLIP,UCF101,0,vision,general,classification
CLIP,Kinetics700,0,vision,general,classification
CLIP,CLEVR Counts,0,multimodal,general,visual_question_answering
CLIP,Hateful Memes,0,multimodal,general,classification
CLIP,Rendered SST2,0,multimodal,general,image_captioning
CLIP,ImageNet-1K,0,vision,general,classification
Gemini Flash 1.5 8B,GPQA,0,language,science,question_answering
Gemini Flash 1.5 8B,MATH,4,language,math,question_answering
Gemini Flash 1.5 8B,BigBench-Hard,3,language,general,question_answering
Gemini Flash 1.5 8B,MMLU,5,language,general,question_answering
Gemini Flash 1.5 8B,Natural2Code,0,language,code,code_generation
Gemini Flash 1.5 8B,MGSM,8,language,math,question_answering
Gemini Flash 1.5 8B,Covost 2,0,multimodal,general,speech_to_text_translation
Gemini Flash 1.5 8B,MMMU,4,multimodal,general,visual_question_answering
Gemini Flash 1.5 8B,DocVQA,0,multimodal,general,visual_question_answering
Gemini Flash 1.5 8B,TextVQA,0,multimodal,general,visual_question_answering
Gemini Flash 1.5 8B,VATEX,4,multimodal,video,visual_question_answering
Claude Sonnet 3.5,GPQA Diamond,0,language,science,question_answering
Claude Sonnet 3.5,MMLU,0,language,general,question_answering
Claude Sonnet 3.5,MMLU,5,language,general,question_answering
Claude Sonnet 3.5,HumanEval,0,language,code,code_generation
Claude Sonnet 3.5,MGSM,0,language,math,question_answering
Claude Sonnet 3.5,DROP,3,language,general,reading_comprehension #REVIEW, QUESTION ANSWERING?
Claude Sonnet 3.5,BigBench-Hard,3,language,general,question_answering
Claude Sonnet 3.5,MATH,0,language,math,question_answering
Claude Sonnet 3.5,GSM8K,0,language,math,question_answering
Llama 3.2,MMMU,0,multimodal,general,visual_question_answering
Llama 3.2,MMMU-Pro,0,multimodal,general,visual_question_answering
Llama 3.2,MathVista,0,multimodal,math,question_answering
Llama 3.2,ChartQA,0,multimodal,general,visual_question_answering
Llama 3.2,AI2 Diagram,0,multimodal,general,visual_question_answering
Llama 3.2,DocVQA,0,multimodal,general,visual_question_answering
Llama 3.2,VQAv2,0,multimodal,general,visual_question_answering
Phi-4-Mini,BigBench-Hard,0,language,general,question_answering
Phi-4-Mini,MMLU,5,language,general,question_answering
Phi-4-Mini,MMLU-Pro,0,language,general,question_answering
Phi-4-Mini,ARC-C,10,language,general,question_answering
Phi-4-Mini,BoolQ,2,language,general,question_answering
Phi-4-Mini,GPQA,0,language,science,question_answering
Phi-4-Mini,HellaSwag,5,language,general,natural_language_inference # REVIEW question answering?
Phi-4-Mini,OpenBookQA,10,language,general,question_answering # review
Phi-4-Mini,PIQA,5,language,general,question_answering
Phi-4-Mini,SIQA,5,language,general,question_answering
Phi-4-Mini,TruthfulQA,10,language,general,question_answering
Phi-4-Mini,WinoGrande,5,language,general,question_answering # REVIEW IF THIS IS A DIFFERENT BENCHMARK
Phi-4-Mini,Multilingual-MMLU,5,language,general,question_answering
Phi-4-Mini,MGSM,0,language,math,question_answering
Phi-4-Mini,GSM8K,8,language,math,question_answering
Phi-4-Mini,MATH,0,language,math,question_answering
Phi-4-Mini,Qasper,0,language,science,question_answering
Phi-4-Mini,SQuALITY,0,language,general,summary_question_answering # REVIEW
Phi-4-Mini,IFEval,0,language,general,instruction_following
Phi-4-Mini,BFCL,0,language,general,function_calling # REVIEW
Phi-4-Mini,HumanEval,0,language,code,code_generation
Phi-4-Mini,MBPP,3,language,code,coding_problems # REVIEW, CODE GENERATION?
Gemma 3,MMLU-Pro,0,language,general,question_answering
Gemma 3,LiveCodeBench,0,language,code,coding_problems
Gemma 3,Bird-SQL (dev),0,language,code,code_generation # REVIEW
Gemma 3,GPQA Diamond,0,language,science,question_answering
Gemma 3,SimpleQA,0,language,general,question_answering
Gemma 3,FACTS Grounding,0,language,general,multiple # REVIEW TASKS (several)
Gemma 3,MATH,0,language,math,question_answering
Gemma 3,HiddenMath,0,language,math,question_answering
Gemma 3,MMMU,0,language,general,visual_question_answering
Gemma 3,DocVQA,4,multimodal,general,visual_question_answering
Gemma 3,InfoVQA,4,language,general,visual_question_answering
Gemma 3,TextVQA,4,multimodal,general,visual_question_answering
Gemma 3,MBPP,3,language,code,coding_problems
Gemma 3,HumanEval,0,language,code,code_generation
Gemma 3,HellaSwag,10,language,general,natural_language_inference # REVIEW question answering?
Gemma 3,BoolQ,0,language,general,question_answering
Gemma 3,PIQA,0,language,general,question_answering
Gemma 3,SIQA,0,language,general,question_answering
Gemma 3,TriviaQA,5,language,general,question_answering
Gemma 3,Natural Questions,5,language,general,question_answering
Gemma 3,ARC-C,25,language,general,question_answering
Gemma 3,ARC-E,0,language,general,question_answering
Gemma 3,WinoGrande,5,language,general,question_answering # REVIEW IF THIS IS A DIFFERENT BENCHMARK
Gemma 3,BigBench-Hard,3,language,general,question_answering
Gemma 3,DROP,1,language,general,reading_comprehension #REVIEW, QUESTION ANSWERING?
Gemma 3,AGIEval,5,language,general,question_answering
Gemma 3,MMLU,5,language,general,question_answering
Gemma 3,MATH,4,language,math,question_answering
Gemma 3,GSM8K,8,language,math,question_answering
Gemma 3,GPQA,5,language,science,question_answering
Gemma 3,MMLU-Pro,5,language,general,question_answering
Gemma 3,MGSM,8,language,math,question_answering
Gemma 3,FloRes,1,language,translation,machine_translation # translation, machine_translation?
Gemma 3,XQuAD,5,language,translation,question_answering # cross lingual question_answering?
Gemma 3,WMT24++,5,language,translation,machine_translation
Gemma 3,ECLeKTic,2,language,translation,question_answering # cross lingual question_answering?
Gemma 3,XQuAD Indic,5,language,translation,multilingual_question_answering # cross lingual question_answering?
Gemma 3,XOR QA IN-EN,5,language,translation,open_retrieval_question_answering # cross lingual question answering?
Gemma 3,XOR QA IN-XX,5,language,translation,open_retrieval_question_answering
Gemma 3,FloRes Indic,5,language,translation,machine_translation
Gemma 3,RULER,0,language,general,multiple
OLMo 2,ARC-C,5,language,general,question_answering
OLMo 2,ARC-E,5,language,general,question_answering
OLMo 2,BoolQ,5,language,general,question_answering
OLMo 2,CommonsenseQA,5,language,general,question_answering
OLMo 2,HellaSwag,5,language,general,natural_language_inference # REVIEW question answering?
OLMo 2,MMLU,5,language,general,question_answering
OLMo 2,OpenbookQA,5,language,general,question_answering # review
OLMo 2,PIQA,5,language,general,question_answering
OLMo 2,SIQA,5,language,general,question_answering
OLMo 2,WinoGrande,5,language,general,question_answering # REVIEW IF THIS IS A DIFFERENT BENCHMARK
OLMo 2,CoQA,0,language,general,question_answering
OLMo 2,DROP,5,language,general,reading_comprehension #REVIEW, QUESTION ANSWERING?
OLMo 2,Jeopardy,5,language,general,question_answering
OLMo 2,Natural Questions,5,language,general,question_answering
OLMo 2,SQuAD,5,language,general,question_answering
OLMo 2,AGIEval,5,language,general,question_answering
OLMo 2,BigBench-Hard,3,language,general,question_answering
OLMo 2,GSM8K,8,language,math,question_answering
OLMo 2,MMLU-Pro,5,language,general,question_answering
OLMo 2,TriviaQA,5,language,general,question_answering
Llama 3,MMLU,0,language,general,question_answering
Llama 3,MMLU,5,language,general,question_answering
Llama 3,MMLU-Pro,5,language,general,question_answering
Llama 3,IFEval,0,language,general,instruction_following
Llama 3,HumanEval,0,language,code,code_generation
Llama 3,MBPP+,0,language,code,coding_problems
Llama 3,GSM8K,8,language,math,question_answering
Llama 3,MATH,0,language,math,question_answering
Llama 3,ARC-C,0,language,general,question_answering
Llama 3,GPQA,0,language,science,question_answering
Llama 3,MGSM,0,language,math,question_answering # MGSM -> math or multilingual?
Tulu 3,MMLU,0,language,general,question_answering
Tulu 3,PopQA,15,language,general,question_answering
Tulu 3,TruthfulQA,6,language,general,question_answering # REVIEW
Tulu 3,BigBench-Hard,3,language,general,question_answering
Tulu 3,DROP,3,language,general,reading_comprehension #REVIEW, QUESTION ANSWERING?
Tulu 3,MATH,4,language,math,question_answering
Tulu 3,GSM8K,8,language,math,question_answering
Tulu 3,HumanEval,0,language,code,code_generation
Tulu 3,HumanEval+,0,language,code,code_generation
Tulu 3,IFEval,0,language,general,instruction_following
AIMv2,ImageNet-1K,1_281_167,vision,general,classification
AIMv2,iNat2018,437_513,vision,ecology,classification
AIMv2,CIFAR-10,50_000,vision,image,classification
AIMv2,CIFAR-100,50_000,vision,image,classification
AIMv2,Food-101,75_750,vision,image,classification
AIMv2,Textures,3_760,vision,image,classification
AIMv2,Oxford-IIIT Pets,3_680,vision,image,classification
AIMv2,Stanford Cars,8_144,vision,image,classification
AIMv2,Chamelyon17,302_436,vision,medical,classification
AIMv2,PatchCamelyon,262_144,vision,medical,classification
AIMv2,RxRx1,40_612,vision,life_science,classification
AIMv2,EuroSAT,16_200,vision,satellite_imagery,classification
AIMv2,fMoW,76_863,vision,satellite_imagery,classification
AIMv2,Infograph,36_023,vision,general,classification # REVIEW
V-JEPA,ImageNet-1K,1_281_167,vision,general,classification
V-JEPA,Kinetics400,245_495,vision,general,classification
V-JEPA,SomethingSomethingV2,168_913,vision,general,classification
V-JEPA,Places205,2_500_000,vision,image,classification
V-JEPA,iNat2021,2_700_000,vision,ecology,classification
V-JEPA,AVA,211_000,vision,general,action_recognition
